---
title: "Campaign Optimisation Notebook Preview"
output: github_document
---
---

### Import necessary packages
```{r}
library(dplyr)
library(caret)
library(xgboost)
library(smotefamily)
library(MLeval)
library(data.table)
library(ggplot2)
library(tidyr)
```

### Read datasets
```{r Reading Data}
campaign_detail = read.csv("Data/Campaign_Detail.csv")
lead_demography = read.csv("Data/Lead_Demography.csv")
market_touchdown = read.csv("Data/Market_Touchdown.csv")
product = read.csv("Data/Product.csv")

```

```{r Data Processing}
market_touchdown_update <- market_touchdown %>%
  mutate(DayofWeek = case_when(
    Day_Of_Week == 1 ~ "Monday",
    Day_Of_Week == 2 ~ "Tuesday",
    Day_Of_Week == 3 ~ "Wednesday",
    Day_Of_Week == 4 ~ "Thursday",
    Day_Of_Week == 5 ~ "Friday",
    Day_Of_Week == 6 ~ "Saturday",
    Day_Of_Week == 7 ~ "Sunday"
  )) %>%
  select(Lead_Id, Channel, Time_Of_Day, DayofWeek, Source, Conversion_Flag, Time_Stamp) %>%
  arrange()


lead_demography_update <- lead_demography %>%
  mutate(Gender = case_when(
    Gender == "F" ~ "Female",
    Gender == "M" ~ "Male"
  )) %>%
  mutate(Marital_Status = case_when(
    Marital_Status == "W" ~ "Widow",
    Marital_Status == "D" ~ "Divorced",
    Marital_Status == "S" ~ "Single",
    Marital_Status == "M" ~ "Married"
  )) %>%
  select(., c(Lead_Id, Age, Annual_Income_Bucket, Credit_Score, Highest_Education,
              Ethnicity, Gender, Marital_Status)) %>%
  arrange()

dataset = inner_join(market_touchdown_update, lead_demography_update, by = c("Lead_Id"))
```


```{r  Display data}
head(data)
```
## Feature Engineering
### Create new feaatures based on the above dataset.

```{r}

last_campaign = dataset %>%
  arrange(Lead_Id, Time_Stamp) %>%
  group_by(Lead_Id) %>%
  summarise(across(everything(), last), .groups = 'drop') %>%
  select(., c(Lead_Id, Channel)) %>%
  rename(Last_Channel = 2)

previous_campaign <- dataset %>%
  mutate(previous_channel= lag(Channel)) %>%
  mutate(previous_channel = replace_na(previous_channel, 'None')) %>%
  select(Lead_Id, previous_channel)

channels_count <- dataset %>%
  mutate(Calling_Count = ifelse(Channel == "Cold Calling", 1, 0)) %>%
  mutate(Email_Count = ifelse(Channel == "Email", 1, 0)) %>%
  mutate(SMS_Count = ifelse(Channel == "SMS", 1, 0)) %>%
  group_by(Lead_Id) %>%
  summarise(cnt_calling = sum(Calling_Count),
            cnt_sms = sum(SMS_Count),
            cnt_email = sum(Email_Count), .groups = 'drop')


channel_hot = model.matrix(~Channel-1,dataset)
timeofday_hot = model.matrix(~Time_Of_Day-1,dataset)
dayofweek_hot = model.matrix(~DayofWeek-1,dataset)
gender_hot = model.matrix(~Gender-1,dataset)
age_hot = model.matrix(~Age-1,dataset)
credit_hot = model.matrix(~Credit_Score-1, dataset)
income_hot = model.matrix(~Annual_Income_Bucket-1, dataset)
marital_status_hot = model.matrix(~Marital_Status-1, dataset)
ethnicity_hot = model.matrix(~Ethnicity-1, dataset)
last_campaign_hot = model.matrix(~Last_Channel-1, last_campaign)
last_campaign_hot = cbind(channels_count %>% select(Lead_Id), last_campaign_hot)
previous_campaign_hot = model.matrix(~previous_channel-1, previous_campaign)

features = cbind(channel_hot, timeofday_hot, dayofweek_hot,
                     age_hot, credit_hot, income_hot,gender_hot,marital_status_hot,
                     ethnicity_hot,previous_campaign_hot,
                     dataset %>% select(Conversion_Flag,  Lead_Id)) %>%
  mutate(Conversion_Flag = case_when(
    Conversion_Flag == 0 ~ "No",
    Conversion_Flag == 1 ~ "Yes")) %>%
  mutate(Conversion_Flag = as.factor(Conversion_Flag)) %>%
  inner_join(., channels_count, by = c("Lead_Id")) %>%
  inner_join(., last_campaign_hot, by = c("Lead_Id")) %>%
  group_by(Lead_Id) %>%
  mutate(order_count = 1:n()) %>%
  ungroup() %>%
  select(., -c(Lead_Id)) %>%
  data.frame() 

head(features)
```
### Train-Test split and Smote for balancing
```{r}
inTraining <- createDataPartition(features$Conversion_Flag, p = .85, list = FALSE)
training <- features[ inTraining,]
testing  <- features[-inTraining,]

train.smote <- SMOTE(training[,-37],training$Conversion_Flag,K = 4)
train_smote <- train.smote$data
```
#### Class Distribution before SMOTE
```{r}
prop.table(table(training$Conversion_Flag))
```


#### Class Distribution after SMOTE
```{r}
prop.table(table(train_smote$class))
```


## Modelling with Cross-Validation and Caret
```{r}
tune_grid <- expand.grid(nrounds = 300,
                         max_depth = 10,
                         eta = 0.05,
                         gamma = 0.01,
                         colsample_bytree = 0.75,
                         min_child_weight = 0,
                         subsample = 0.5)

fitControl <- trainControl(method = "cv",
                           number = 5,
                           classProbs = TRUE,
                           savePredictions = TRUE,
                           summaryFunction = twoClassSummary)

gbmFit1 <- train(class ~ ., data = train_smote, 
                 method = "xgbTree", 
                 trControl = fitControl,
                 verbose = TRUE,
                 metric = "Sens",
                 tuneGrid = tune_grid,
                 tuneLength = 10)
```

### Save Models
```{r}
saveRDS(gbmFit1, "xgboost_model.rds")
```

## Classifier Evaluation

### Confusion matrix
```{r}
test_predictions = predict(gbmFit1, newdata = testing %>% select(-c(Conversion_Flag)))
cm = confusionMatrix(test_predictions, testing$Conversion_Flag,positive = "Yes")
cm
```


```{r}
table <- as.data.frame(cm$table)

plotTable <- table %>%
  mutate(goodbad = ifelse(table$Prediction == table$Reference, "good", "bad")) %>%
  group_by(Reference) %>%
  mutate(prop = Freq/sum(Freq))

# fill alpha relative to sensitivity/specificity by proportional outcomes within reference groups (see dplyr code above as well as original confusion matrix for comparison)
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(good = "#7DCEA0", bad = "#EC7063")) +
  theme_bw() +
  xlim(rev(levels(table$Reference)))
```
## ROC Curve
#### We choose the AUC-PR since we are more interested in the positive class
```{r}
test_predictions = predict(gbmFit1, newdata = testing %>% select(-c(Conversion_Flag)), type = "prob")
roc_test = evalm(data.frame(test_predictions, testing$Conversion_Flag))
roc_test$proc
```
### Misclassified Campaigns
```{r}
test_predictions = predict(gbmFit1, newdata = testing %>% select(-c(Conversion_Flag)))
false_negatives = cbind(test_predictions, testing) %>%
  filter(Conversion_Flag == "Yes" & test_predictions == "No")
head(false_negatives)

false_positives = cbind(test_predictions, testing) %>%
  filter(Conversion_Flag == "No" & test_predictions == "Yes")
head(false_positives)
```

